\section{Лекция 5}

\subsection{Информация Фишера}
\begin{definition}
	Пусть $S(\vec{X})$ "--- это некоторая статистика с плотностью $g_{\theta}(x)$. Тогда \emph{информацией Фишера} статистики $S(\vec{X})$ называется
	\[
		I_{S}(\theta) = \EE_{\theta}\left[\left(\pdv{\theta} \ln g_{\theta}(S(\vec{X}))\right)^{2}\right].
	\]
\end{definition}
У информации Фишера есть несколько свойств, которые оправдывают её название.
\begin{enumerate}
	\item Допустим, что распределение $S(\vec{X})$ не зависит от $\theta$. Тогда $I_{S}(\theta) = 0$.
\end{enumerate}
\begin{proof}
	Это достаточно очевидное утверждение, так как в таком случае $\ln g_{\theta}(S(\vec{X}))$ не будет зависеть от $\theta$ и при дифференцировании по нему обратится в 0, а матожидание нуля есть ноль.
\end{proof}
\begin{enumerate}[resume]
	\item Пусть $S(\vec{X})$ и $T(\vec{X})$ "--- независимые статистики для всех $\theta \in \Theta$ и выполнены условия регулярности. Тогда
	\[
		I_{(S, T)}(\theta) = I_{S}(\theta) + I_{T}(\theta).
	\]
\end{enumerate}
\begin{proof}
	Пусть статистики $S(\vec{X})$ и $T(\vec{X})$ имеют плотности $f_{\theta}(s)$ и $g_{\theta}(t)$ соответственно. Тогда случайный вектор $(S(\vec{X}), T(\vec{X}))$ имеет совместную плотность $h_{\theta}(s, t) = f_{\theta}(s)g_{\theta}(t)$. Следовательно,
	\[
		\ln h_{t}(s, t) = \ln f_{\theta}(s) + \ln g_{\theta}(t).
	\]
	Из этого можно сделать вывод, что
	\[
		\EE_{\theta}\left[\pdv{\theta} \ln h_{\theta}(S(\vec{X}), T(\vec{X}))\right] 
		= \EE_{\theta}\left[\pdv{\theta} \ln f_{\theta}(S(\vec{X}))\right] + \EE_{\theta}\left[\pdv{\theta} \ln g_{\theta}(T(\vec{X}))\right]
		= 0.
	\] 
	Но тогда
	\begin{align*}
		I_{(S, T)}(\theta) 
		&= \DD_{\theta}\left[\pdv{\theta} \ln h_{\theta}(S(\vec{X}), T(\vec{X}))\right] \\
		&= \DD_{\theta}\left[\pdv{\theta} \ln f_{\theta}(S(\vec{X}))\right] + \DD_{\theta}\left[\pdv{\theta} \ln g_{\theta}(T(\vec{X}))\right]
		= I_{S}(\theta) + I_{T}(\theta). \qedhere
	\end{align*}
\end{proof}
У этого свойства есть 2 следствия. 
\begin{consequence}
\[
	i(\theta) = \EE_{\theta}\left[\left(\pdv{\theta} \ln p_{\theta}(X_{1})\right)^{2}\right].
\]
Тогда
\[
	I_{\vec{X}}(\theta) = \sum_{i = 1}^{n} I_{X_{i}}(\theta) = nI_{X_{1}}(\theta) = ni(\theta).
\]
\end{consequence}

\begin{consequence}
В неравенсте Рао-Крамера в случае выборки правая часть неравенства
\[
\frac{(\tau'(\theta))^2}{I_{\vec{X}}(\theta)} = \frac{(\tau'(\theta))^2}{ni(\theta)} = |\text{если } \tau(\theta) \text{ не зависит от n}| = \Theta(\frac{1}{n}) 
\]
\end{consequence}
\begin{enumerate}[resume]
	\item Для любой статистики $S(\vec{X})$ $I_{S}(\theta) \leq I_{\vec{X}}(\theta)$.
\end{enumerate}
\begin{proof}
	Это свойство б/д, так как нужно условное матожидание.
\end{proof}
\begin{enumerate}[resume]
	\item Оценка $S(\vec{X})$ будет достаточной тогда и только тогда, когда для всех $\theta \in \Theta$ $I_{S}(\theta) = I_{\vec{X}}(\theta)$.
\end{enumerate}
\begin{proof}
	Это свойство будет доказано позднее.
\end{proof}

Вывод: Эффективная оценка $\tau(\theta)$ -- наилучшая оценка в равномерном подходе, с квадратичной функцией потерь в классе несмещенных оценок $\tau(\theta)$.

Минусы:
\begin{itemize}
    \item Необходимо выполнение условий регулярности.
    \item Эффективная оценка существует максимум для одной функции $\tau(\theta)$ из данного параметрического семейства.
    \item В случае выборки скорость убывания дисперсии $\Theta(\frac{1}{n})$
\end{itemize}

Рассмотрим пример.
\begin{problem}
	Пусть $\vec{X} = (X_{1}, \ldots, X_{n})$ "--- выборка из экспоненциального распределения $\mathrm{Exp}(\theta)$. Далее, пусть $X_{(1)} = \min_{1 \leq i \leq n} X_{i}$. Найти $I_{X_{(1)}}(\theta)$ и $I_{\vec{X}}(\theta)$.
\end{problem}
\begin{proof}[Решение]
	Начнём с того, что найдём распределение $X_{(1)}$. Для этого заметим, что
	\[
		\Pr_{\theta}(X_{(1)} \leq x) = 1 - \Pr_{\theta}(X_{(1)} \geq x) = 1 - \prod_{i = 1}^{n} \Pr_{\theta}(X_{i} \geq x) = 1 - e^{-n\theta x}.
	\]
	Следовательно, $X_{(1)} \sim \mathrm{Exp}(n\theta)$. 
	
	Теперь можно считать информации Фишера. Начнём с $I_{\vec{X}}(\theta)$. Вспомним, что $I_{\vec{X}}(\theta) = ni(\theta)$. Тогда
	\[
		\pdv{\theta} \ln p_{\theta}(X_{1}) = \pdv{\theta}(\ln \theta - \theta X_{1}) = \frac{1}{\theta} - X_{1}.
	\]
	Тогда
	\[
		i(\theta) = \EE_{\theta}\left[\left(X_{1} - \frac{1}{\theta}\right)^{2}\right] = \DD_{\theta}[X_{1}] = \frac{1}{\theta^{2}} \implies I_{\vec{X}}(\theta) = \frac{n}{\theta^{2}}.
	\]
	
	Теперь посчитаем $I_{X_{(1)}}(\theta)$ аналогичным образом. Заметим, что
	\[
		\pdv{\theta} \ln p_{\theta}(X_{(1)}) = \pdv{\theta}(\ln n + \ln \theta - n\theta X_{1}) = \frac{1}{\theta} - nX_{1}.
	\]
	Тогда 
	\[
		I_{X_{1}}(\theta) = \EE_{\theta}\left[\left(nX_{(1)} - \frac{1}{\theta}\right)^{2}\right] = n^{2}\DD_{\theta}[X_{(1)}] = \frac{1}{\theta^{2}}. \qedhere
	\]
\end{proof}

\subsection{Метод максимального правдоподобия}

Сегодня мы будем обсуждать то, что преобразило статистику "--- метод максимального правдоподобия. Начнём с того, что введём понятие правдоподобия.
\begin{definition}
    Пусть $\vec{X} = (X_{1}, \ldots, X_{n})$ "--- наблюдение с неизвестным распределением $\Pr \in \{\Pr_{\theta}, \theta \in \Theta\}$, где $\{\Pr_{\theta}, \theta \in \Theta\}$ есть доминируемое семейство с обобщённой плотностью $p_{\theta}(\vec{x})$. Тогда \emph{функцией правдоподобия} называется случайная величина $f_{\theta}(\vec{X}) = p_{\theta}(\vec{X})$.
\end{definition}
\begin{remark}
    Если $\vec{X} = (X_{1}, \ldots, X_{n})$ "--- выборка, то плотность случайного вектора разбивается в произведение плотностей координат:
    \[
        f_{\theta}(\vec{X}) = p_{\theta}(\vec{X}) = \prod_{i = 1}^{n} p_{\theta}(X_{i}).
    \]
\end{remark}
Теперь можно ввести и сам метод.
\begin{definition}
    Оценкой параметра $\theta$ по методу максимального правдоподобия, или же \emph{оценкой максимального правдоподобия}, называется
    \[
        \hat{\theta}(\vec{X}) = \arg\max_{\theta \in \Theta} f_{\theta}(\vec{X}).
    \]
\end{definition}

\begin{remark}
    Если максимум не достигается, то ОМП нет.
\end{remark}

\begin{remark}
    Если во многих точках достигается максимум, то надо <<добавить данных>>. сюда картинку.
\end{remark}
Данное определение уже накладывает несколько ограничений: как минимум, то, что максимум существует и он единственен. Но в дальнейшем будем считать, что они выполнены. Философия этого метода уже не так очевидна. Она состоит в том, что <<мы живём в наиболее вероятном мире>>.

Допустим, что мы рассматриваем схему Бернулли и у нас выпало много нулей и мало единиц. Мы думаем: <<Наверное, это неспроста!>> Тогда, наверное, так и должно быть на самом деле "--- действительно, в дискретном случае функция правдоподобия есть вероятность того, что выпадает данный набор. Далее, мы подбираем $\theta$ такое, что данный набор наблюдений наиболее вероятен "--- коли уж он выпал, то истинным значением должно быть только то, в котором он выпадает с наибольшей вероятностью.

Рассмотрим пару примеров нахождения оценки максимального правдоподобия, для того, чтобы понять, что вообще происходит.
\begin{problem}
    Пусть $\vec{X} = (X_{1}, \ldots, X_{n})$ "--- выборка из равномерного распределения $\mathrm{U}(0, \theta)$, $\theta > 0$. Найти оценку максимального правдоподобия параметра $\theta$.
\end{problem}
\begin{proof}[Решение]
    Начнём с того, что распишем функцию правдоподобия:
    \[
        f_{\theta}(\vec{X}) = \prod_{i = 1}^{n} p_{\theta}(X_{i}) = \prod_{i = 1}^{n} \frac{1}{\theta}[0 \leq X_{i} \leq \theta] = \frac{1}{\theta^{n}}[0 \leq X_{(1)} \leq X_{(n)} \leq \theta].
    \]
    Теперь нам нужно максимизировать её, как функцию от $\theta$. Заметим, что $\theta^{-n}$ есть монотонно убывающая функция, поэтому нужно взять минимальное $\theta$ такое, что функция правдоподобия не обратится в ноль. Но тогда $\hat{\theta}(\vec{X}) = X_{(n)}$.
\end{proof}

\begin{problem}
    Пусть $\vec{X} = (X_{1}, \ldots, X_{n})$ "--- выборка из нормального распределения $\mathcal{N}(\mu, \sigma^{2})$. Найдите оценку максимального правдоподобия параметра $\vec{\theta} = (\mu, \sigma^{2})$.
\end{problem}
\begin{proof}[Решение]
    Опять же, начнём с того, что распишем функцию правдоподобия:
    \[
        f_{\vec{\theta}}(\vec{X}) 
        = \prod_{i = 1}^{n} p_{\vec{\theta}}(X_{i}) 
        = \prod_{i = 1}^{n} \frac{1}{\sqrt{2\pi\sigma^{2}}}\exp\left\{-\frac{(X_{i} - \mu)^{2}}{2\sigma^{2}}\right\}
        = \left(\frac{1}{\sqrt{2\pi\sigma^{2}}}\right)^{n} \exp\left\{-\frac{1}{2\sigma^{2}} \sum_{i = 1}^{n} (X_{i} - \mu)^{2}\right\}.
    \]
    
    Нам нужно максимизировать её одновременно по $\mu$ и по $\theta$. Но работать с экспонентой достаточно неудобно, поэтому прологарифмируем её. Это не поменяет решения, так как логарифм биективно переводит $\mathbb{R}_{++}$ в $\mathbb{R}$:
    \[
        \ln f_{\vec{\theta}}(\vec{X})
        = -\frac{n}{2}\ln 2\pi - \frac{n}{2}\ln \sigma^{2} - \frac{1}{2\sigma^{2}} \sum_{i = 1}^{n} (X_{i} - \mu)^{2}.
    \]
    Эта функция дифференцируема, поэтому можно достаточно легко найти всех претендентов на точки экстремума приравниванием производной к нулю:
    \begin{align*}
        0 = \pdv{\mu} \ln f_{\vec{\theta}}(\vec{X})
        &= \frac{1}{\sigma^{2}}\sum_{i = 1}^{n} (X_{i} - \mu), \\
        0 = \pdv{\sigma^{2}} \ln f_{\vec{\theta}}(\vec{X})
        &= -\frac{n}{2\sigma^{2}} + \frac{1}{2\sigma^{4}}\sum_{i = 1}^{n} (X_{i} - \mu)^{2}.
    \end{align*}
    Отсюда несложно получить, что претендентами на точки экстремума будут 
    \begin{align*}
        \hat{\mu}(\vec{X}) 
        &= \frac{1}{n}\sum_{i = 1}^{n} X_{i} = \overline{\vec{X}}, \\
        \hat{\sigma}^{2}(\vec{X})
        &= \frac{1}{n}\sum_{i = 1}^{n} \left(X_{i} - \frac{1}{n}\sum_{i = 1}^{n} X_{i}\right)^{2} = S^{2}.
    \end{align*}
    Но данная точка действительно будет являться максимумом, что несложно проверить по значениям производных. Так как она есть единственный максимум, то это глобальный максимум и $\hat{\theta}(\vec{X}) = (\overline{\vec{X}}, S^{2})$.
\end{proof}

Вывод: нахождение ОМП -- это задача оптимизации!\\\

У оценок максимального правдоподобия и функции правдоподобия есть достаточно интересные свойства. Но они требуют некоторых условий регулярности. Будем постепенно формулировать их и доказывать свойства.
\begin{enumerate}[label=(R\arabic*)]
    \item Параметрическое семейство распределений $\set{\Pr_{\theta} \mid \theta \in \Theta}$ "--- это доминируемое семейство с плотностью $p_{\theta}(x)$ и \emph{различимыми распределениями}, то есть $\Pr_{\theta_{0}} = \Pr_{\theta_{1}}$ почти везде тогда и только тогда, когда $\theta_{0} = \theta_{1}$.
    
    \item $\vec{X} = (X_{1}, \ldots, X_{n})$ "--- выборка растущего размера из неизвестного распределения $\Pr \in \set{\Pr_{\theta} \mid \theta \in \Theta}$.
    
    \item $A = \set{x \colon p_{\theta}(x) > 0}$ не зависит от $\theta$.
\end{enumerate}

\begin{theorem}[Экстремальное свойство правдоподобия]
    В условиях регулярности (R1)"--~(R3) для всех различных $\theta_{0}$, $\theta_{1} \in \Theta$
    \[
        \lim\limits_{n \to \infty} \Pr_{\theta_{0}}(f_{\theta_{0}}(\vec{X}) > f_{\theta_{1}}(\vec{X})) = 1.
    \]
\end{theorem}
\begin{proof}
    Будем считать, что мы будем работаем в $A$. Посмотрим, при каких условиях выполняется событие $f_{\theta_{0}}(\vec{X}) > f_{\theta_{1}}(\vec{X})$. Для этого прологарифмируем и преобразуем выражение:
    \[
        \ln \frac{f_{\theta_{1}}(\vec{X})}{f_{\theta_{0}}(\vec{X})} < 0 \implies \frac{1}{n}\sum_{i = 1}^{n} \ln \frac{p_{\theta_{1}}(X_{i})}{p_{\theta_{0}}(X_{i})} < 0.
    \]
    По усиленному закону больших чисел
    \[
        \frac{1}{n}\sum_{i = 1}^{n} \ln \frac{p_{\theta_{1}}(X_{i})}{p_{\theta_{0}}(X_{i})} \xrightarrow{\Pr_{\theta_{0}}\text{-п.н.}} \EE_{\theta_{0}}\left[\ln \frac{p_{\theta_{1}}(X_{1})}{p_{\theta_{0}}(X_{1})}\right].
    \]
    Теперь докажем, что
    \[
        \EE_{\theta_{0}}\left[\ln \frac{p_{\theta_{1}}(X_{1})}{p_{\theta_{0}}(X_{1})}\right] < 0.
    \]
    Воспользуемся неравенством Йенсена:
    \[
        \EE_{\theta_{0}}\left[\ln \frac{p_{\theta_{1}}(X_{1})}{p_{\theta_{0}}(X_{1})}\right]
        \leq \ln \EE_{\theta_{0}}\left[ \frac{p_{\theta_{1}}(X_{1})}{p_{\theta_{0}}(X_{1})} \right] 
        = \ln \int_{A} \frac{p_{\theta_{1}}(X_{1})}{p_{\theta_{0}}(X_{1})} p_{\theta_{0}}(X_{1})\mu(\dd x) = \ln \EE_{\theta_{1}}[1] = 0.
    \]
    Но почему оно не равно нулю? Предположим, что это так:
    \[
        \EE_{\theta_{0}}\left[\ln \frac{p_{\theta_{1}}(X_{1})}{p_{\theta_{0}}(X_{1})}\right] = 0.
    \]
    Но в таком случае можно воспользоваться критерием равенства для неравенства Йенсена: $\phi(\EE[\xi]) = \EE[\phi(\xi)]$ тогда и только тогда, когда $\phi$ линейна почти везде. Но $\ln(x)$ нелинейна. Тогда получаем, что аргумент должен быть равен единице почти везде: $\mu(\set{x \colon p_{\theta_{0}}(x) = p_{\theta_{1}}(x)}) = 1$. Но это означает, что $\theta_{0} = \theta_{1}$, что противоречит условию. 
    
    В итоге получаем, что
    \[
        \lim\limits_{n \to \infty} \Pr_{\theta_{0}}(f_{\theta_{0}}(\vec{X}) > f_{\theta_{1}}(\vec{X})) 
        = \Pr_{\theta_{0}}\left(\EE_{\theta_{0}}\left[\ln \frac{p_{\theta_{1}}(X_{1})}{p_{\theta_{0}}(X_{1})}\right] < 0\right) = 1. \qedhere
    \]
\end{proof}
\begin{consequence}[Состоятельность оценки максимального правдоподобия]
    Если $\Theta$ конечно, что оценка максимального правдоподобия состоятельна.
\end{consequence}
\begin{proof}
    Пусть $\hat{\theta}_{n}(\vec{X})$ "--- это оценка максимального правдоподобия. Тогда по экстремальному свойству правдоподобия для любого $\theta_{0} \in \Theta$
    \[
        \lim\limits_{n \to \infty} \Pr_{\theta_{0}}(\hat{\theta}_{n}(\vec{X}) = \theta_{0}) 
        = \lim\limits_{n \to \infty} \Pr_{\theta}(\forall \theta \neq \theta_{0} f_{\theta_{0}}(\vec{X}) > f_{\theta}(\vec{X}))
        = 1. \qedhere
    \]
\end{proof}

Введём ещё два условия регулярности:
\begin{enumerate}[label=(R\arabic*), start=4]
    \item $\Theta$ есть открытый интервал на $\mathbb{R}$.
    \item $p_{\theta}(x)$ непрерывно дифференцируема по $\theta$ для всех $x \in A$.
\end{enumerate}
Теперь можно доказать хорошее свойство, плотно связанное с оценками максимального правдоподобия.
\begin{theorem}[Состоятельность решения уравнения правдоподобия]
    В условиях регулярности (R1)"--~(R5) \emph{уравнение правдоподобия}
    \[
        \pdv{\theta}\ln f_{\theta}(\vec{X}) = 0
    \]
    с вероятностью, стремящейся к 1, имеет решение, которое сходится по вероятности к истинному значению параметра.
\end{theorem}
\begin{proof}
    Пусть $\theta_{0}$ есть истинное значение параметра. Возьмём $\delta > 0$ такое, что $[\theta_{0} - \delta, \theta_{0} + \delta] \subset \Theta$ (это возможно из-за открытости $\Theta$). Далее, введём следующее событие:
    \[
        A_{n} = \set{f_{\theta_{0}}(\vec{X}) > f_{\theta_{0} + \delta}(\vec{X}), f_{\theta_{0}}(\vec{X}) > f_{\theta_{0} - \delta}(\vec{X})}
    \]
    Тогда по экстремальному свойству правдоподобия
    \[
        \lim\limits_{n \to \infty} \Pr_{\theta_{0}}(A_{n}) = 1.
    \]
    Что можно сказать, если выполнено $A_{n}$? Так как по (R6) производная логарифма функции правдоподобия непрерывна по $\theta$, то на отрезке $[\theta_{0} - \delta, \theta_{0} + \delta]$ будет точка, в которой возрастание заменяется убыванием. Следовательно, на нём будет хотя бы один корень уравнения правдоподобия. Допустим, что на этом отрезке есть несколько корней (не обязательно конечное число). Пусть $\tilde{\theta}(\vec{X})$ "--- ближайший к $\theta_{0}$ корень. Это возможно, так как предел корней тоже является корнем (так как производная непрерывна). Тогда оказывается, что для всех $\epsilon > 0$
    \[ 
        \lim\limits_{n \to \infty} \Pr_{\theta_{0}}(|\tilde{\theta}(\vec{X}) - \theta_{0}| \leq \epsilon) 
        = 1.
    \]
    Почему это так? Зафиксируем $\epsilon$ и заметим, что рассуждения выше легальны для $\delta = \epsilon$. Следовательно, с вероятностью, стремящейся к 1, на отрезке $[\theta_{0} - \epsilon, \theta_{0} + \epsilon]$ будет корень. Но $\tilde{\theta}(\vec{X})$ "--- ближайший к $\theta_{0}$ корень. Тогда он лежит в этом отрезке.
\end{proof}
Вот доказали мы эту теорему. Но она больше напоминает решето, из которого вытекают проблемы. Почему?
\begin{enumerate}
    \item Например, корней уравнения правдоподобия может быть несколько. В доказательстве мы выбираем ближайший из них к истинному значению. Но как его выбрать?
    \item Даже если мы его найдём, то он зависит от истинного значения, то есть вообще не является оценкой.
    \item Почему $\tilde{\theta}(\vec{X})$ есть точка максимума? Мы сказали, что это корень уравнения, но он не обязательно даёт максимум "--- может оказаться, что это точка минимума или же точка перегиба (если корней несколько).
    \item Корень существует не всегда, а только с большой вероятностью.
\end{enumerate}
Впрочем, если сказать, что уравнение правдоподобия имеет только один корень, то всё достаточно неплохо. Четвёртый и второй вопросы отпадают сразу же, да и первый тоже. Остался третий, но он тоже исправляется:

\begin{theorem}
    Если для всех $\vec{X} = (X_{1}, \ldots, X_{n})$ уравнение правдоподобия имеет единственный корень $\hat{\theta}(\vec{X})$, то с вероятностью, стремящейся к 1, $\hat{\theta}(\vec{X})$ будет оценкой максимального правдоподобия и онценка максимального правдоподобия будет состоятельной.
\end{theorem}
\begin{proof}
    По сути, доказательство повторяет то, что было сказано выше. Пусть $\theta_{0}$ "--- истинное значение параметра. Снова возьмём $\delta > 0$ такое, что $[\theta_{0} - \delta, \theta_{0} + \delta] \subset \Theta$ и заметим, что если 
    \[
        \lim\limits_{n \to \infty} \Pr_{\theta_{0}}(A_{n}) 
        = 1, 
        \text{ где } A_{n} 
        = \set{f_{\theta_{0}}(\vec{X}) > f_{\theta_{0} + \delta}(\vec{X}), f_{\theta_{0}}(\vec{X}) > f_{\theta_{0} - \delta}(\vec{X})}.
    \]
    Однако если выполнено $A_{n}$, то внутри $[\theta_{0} - \delta, \theta_{0} + \delta]$ есть точка локального максимума. Как известно, в ней производная равна нулю, и, следовательно, она будет корнем уравнения правдоподобия. Но тогда эта точка есть $\hat{\theta}(\vec{X})$. Далее, это должен быть глобальный максимум, так как иначе найдётся локальный минимум, что противоречит единственности корня. Следовательно, если выполнено $A_{n}$, то $\hat{\theta}(\vec{X})$ есть оценка максимального правдоподобия. Тогда
    \[
        \lim\limits_{n \to \infty} \Pr_{\theta_{0}}(\hat{\theta}(\vec{X}) = \text{ОМП}) 
        = 1.
    \]
    Но, как известно, $\hat{\theta}(\vec{X})$ есть ближайший к $\theta_{0}$ корень. Тогда для всех $\epsilon > 0$
    \[
        \lim\limits_{n \to \infty} \Pr_{\theta_{0}}(|\hat{\theta}(\vec{X}) - \theta_{0}| \leq \epsilon) 
        = 1.
    \]
    Тем самым получаем, что и ОМП будет состоятельной оценкой параметра $\theta$.
\end{proof}

Поехали дальше. Эти условия регулярности уже далеко не так очевидны на первый взгляд.
\begin{enumerate}[label=(R\arabic*), start=6]
    \item $p_{\theta}(x)$ трижды непрерывно дифференцируема по $\theta$ для всех $x \in A$.
    \item Интеграл
    \[
        \int_{A} p_{\theta}(x)\mu(\dd x)
    \]
    можно дважды дифференцировать под знаком интеграла.
    \item Для всех $\theta \in \Theta$
    \[
        0 < i(\theta) = \EE_{\theta}\left[\left(\pdv{\theta}\ln p_{\theta}(X_{1})\right)^{2}\right] < +\infty.
    \]
    \item Для любого $\theta_{0} \in \Theta$ существует $\delta > 0$ и функция $M(x)$ такая, что для всех $\theta \in [\theta_{0} - \delta, \theta_{0} + \delta]$
    \[
        \left|\pdv[3]{\theta} \ln p_{\theta}(x)\right| \leq M(x), 
        \text{ причём } 
        \EE_{\theta_{0}}[M(X_{1})] < +\infty.
    \]
\end{enumerate}
\begin{theorem}
    В условиях регулярности (R1)"--~(R9) любая состоятельная последовательность $\set{\hat{\theta}_{n}(\vec{X}) \mid n \in \mathbb{N}}$ корней уравнения правдоподобия удовлетворяет свойству асимптотической нормальности: для всех $\theta_{0} \in \Theta$
    \[
        \sqrt{n}(\hat{\theta}_{n}(\vec{X}) - \theta_{0}) 
        \xrightarrow{d_{\theta_{0}}} \mathcal{N}\left(0, \frac{1}{i(\theta_{0})}\right).
    \]
\end{theorem}

\begin{consequence}
    Если в условиях теоремы для всех $\vec{X} = (X_{1}, \ldots, X_{n})$ существует единственное решение уравнения правдоподобия, то оно является оценкой максимального правдоподобия, причём ОМП будет асимптотически нормальной оценкой параметра $\theta$ с асимптотической дисперсией $i^{-1}(\theta)$.
\end{consequence}

Оказывается, что можно предложить нижнюю границу не только для обычной дисперсии (что даёт неравенство Рао-Крамера), но и для асимптотической дисперсии. Этот результат называется \emph{теоремой Бахадура}. Сформулируем его:
\begin{theorem}[Бахадур]
    Если в условиях регулярности (R1)"--~(R9) оценка $\hat{\theta}(\vec{X})$ является асимптотически нормальной оценкой параметра $\theta$ с асимптотической дисперсией $\sigma^{2}(\theta)$, то $\sigma^{2}(\theta) \geq i^{-1}(\theta)$ почти везде (то есть неравенство нарушается только на множестве лебеговой меры 0).
\end{theorem}

\begin{definition}
    Асимптотически нормальной оценкой $\theta$ называется фсимптотически эффективной, если её асимптотическая дисперсия есть $\frac{1}{i(\theta)}$
\end{definition}

Выводы:
\begin{itemize}
    \item ОМП асимптотически эффективна(в условиях регулярности).
    \item ОМП --- наилучшая оценка в асимптотическом подходе.
\end{itemize}

\begin{theorem}[Эффективность оценки максимального правдоподобия]
    Если в условиях неравенства Рао-Крамера $\hat{\theta}(\vec{X})$ является эффективной оценкой $\theta$, то $\hat{\theta}(\vec{X})$ есть оценка максимального правдоподобия.
\end{theorem}
\begin{proof}
    Воспользуемся критерием эффективности оценки:
    \[
        \hat{\theta}(\vec{X}) - \theta = \frac{1}{I_{\vec{X}}(\theta)}\frac{\partial}{\partial\theta}\ln p_{\theta}(\vec{X}) = \frac{\Ell(\theta, \vec{X})}{I_{\vec{X}}(\theta)}.
    \]
    Так как информация Фишера положительна, то $\Ell(\theta, \vec{X})$ имеет тот же знак, что и $\hat{\theta}(\vec{X}) - \theta$: при $\theta < \hat{\theta}(\vec{X})$ $\Ell(\theta, \vec{X}) > 0$ и наоборот. Тогда получаем, что $\hat{\theta}(\vec{X})$ "--- это единственная точка максимума $f_{\theta}(\vec{X})$ (как функции от $\theta$), то есть $\hat{\theta}(\vec{X})$ есть оценка максимального правдоподобия.
\end{proof}
